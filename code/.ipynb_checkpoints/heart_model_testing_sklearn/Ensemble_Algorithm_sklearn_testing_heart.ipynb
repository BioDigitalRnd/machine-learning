{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77252fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest = 81.967%\n",
      "DecisionTree = 81.967%\n",
      "GradBoosting = 78.689%\n",
      "ExtraTrees = 80.328%\n",
      "HistGradient = 78.689%\n"
     ]
    }
   ],
   "source": [
    "# Comparison of classification algorithms from sklearn\n",
    "\n",
    "# import algorithms\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier,\n",
    "StackingClassifier, VotingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read data and assign independent and dependent variables\n",
    "heart_data = pd.read_csv('heart.csv')\n",
    "X = heart_data.drop(columns=['target'])\n",
    "y = heart_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) #split data in two parts\n",
    "\n",
    "\n",
    "# apply algorithms to data\n",
    "model_R = RandomForestClassifier()\n",
    "model_R.fit(X_train, y_train)\n",
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_train, y_train)\n",
    "model_G = GradientBoostingClassifier()\n",
    "model_G.fit(X_train, y_train)\n",
    "# model_E = ExtraTreeClassifier()\n",
    "# model_E.fit(X_train, y_train)\n",
    "model_ES = ExtraTreesClassifier()\n",
    "model_ES.fit(X_train, y_train)\n",
    "# model_B = BaggingClassifier()\n",
    "# model_B.fit(X_train, y_train)\n",
    "# model_A = AdaBoostClassifier()\n",
    "# model_A.fit(X_train, y_train)\n",
    "# model_D = DummyClassifier()\n",
    "# model_D.fit(X_train, y_train)\n",
    "# model_I = IsolationForest()\n",
    "# model_I.fit(X_train, y_train)\n",
    "model_H = HistGradientBoostingClassifier()\n",
    "model_H.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# model_S = StackingClassifier() #requires estimators as inputs\n",
    "# model_S.fit(X_train, y_train)\n",
    "# model_V = VotingClassifier()  #requires estimators as inputs\n",
    "# model_V.fit(X_train, y_train)\n",
    "\n",
    "#make predictions using test data\n",
    "predictions_R = model_R.predict(X_test)\n",
    "predictions_DT = model_DT.predict(X_test)\n",
    "predictions_G = model_G.predict(X_test)\n",
    "# predictions_E = model_E.predict(X_test)\n",
    "predictions_ES = model_ES.predict(X_test)\n",
    "# predictions_B = model_B.predict(X_test)\n",
    "# predictions_A = model_A.predict(X_test)\n",
    "# predictions_D = model_D.predict(X_test)\n",
    "# predictions_I = model_I.predict(X_test)\n",
    "predictions_H = model_H.predict(X_test)\n",
    "\n",
    "\n",
    "# predictions_S = model_S.predict(X_test)\n",
    "# predictions_V = model_V.predict(X_test)\n",
    "\n",
    "#compare predictions with real values\n",
    "score_R = accuracy_score(y_test, predictions_R)\n",
    "score_DT = accuracy_score(y_test, predictions_DT)\n",
    "score_G = accuracy_score(y_test, predictions_G)\n",
    "# score_E = accuracy_score(y_test, predictions_E)\n",
    "score_ES = accuracy_score(y_test, predictions_ES)\n",
    "# score_B = accuracy_score(y_test, predictions_B)\n",
    "# score_A = accuracy_score(y_test, predictions_A)\n",
    "# score_D = accuracy_score(y_test, predictions_D)\n",
    "# score_I = accuracy_score(y_test, predictions_I)\n",
    "score_H = accuracy_score(y_test, predictions_H)\n",
    "\n",
    "\n",
    "# score_S = accuracy_score(y_test, predictions_S)\n",
    "# score_V = accuracy_score(y_test, predictions_V)\n",
    "\n",
    "#display algorithms accuracy score (between 0-1; 0 being completely inaccurate, 1 being completey accurate)\n",
    "print(f\"RandomForest = {score_R*100:.3f}%\")\n",
    "print(f\"DecisionTree = {score_DT*100:.3f}%\")\n",
    "print(f\"GradBoosting = {score_G*100:.3f}%\")\n",
    "# print(\"ExtraTree = \",score_E)\n",
    "print(f\"ExtraTrees = {score_ES*100:.3f}%\")\n",
    "# print(\"Bagging = \",score_B)\n",
    "# print(\"Adaboost = \",score_A)\n",
    "# print(\"Dummy = \",score_D)\n",
    "# print(\"IsolationForest = \",score_I)\n",
    "print(f\"HistGradient = {score_H*100:.3f}%\")\n",
    "\n",
    "\n",
    "# print(\"Stacking = \",score_S)\n",
    "# print(\"Voting = \",score_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ebca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
